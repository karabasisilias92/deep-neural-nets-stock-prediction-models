{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Simple S&P 500.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "g4okRUVaQ2-M"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks/nn/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swGogYjVR0OX"
      },
      "source": [
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/MyDrive/Colab Notebooks/nn/\"\n",
        "%cd /content/gdrive/MyDrive/Colab\\ Notebooks/nn\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D-PmZbAV-IP"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime as dt\n",
        "import urllib.request, json\n",
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf # This code has been tested with TensorFlow 1.6\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "filename = \"all_stocks_5yr.csv\"\n",
        "original_data = pd.read_csv(filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_DjLtB1WVBx"
      },
      "source": [
        "original_data.describe()\n",
        "original_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hu64a6ReWaHA"
      },
      "source": [
        "from matplotlib.dates import AutoDateFormatter, AutoDateLocator, date2num\n",
        "\n",
        "len(original_data['Name'].unique())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDz7mr7zsiaw"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def generate_series(data, value_num):\n",
        "    min = data.min()[\"close\"]\n",
        "    max = data.max()[\"close\"]\n",
        "    close = (data['close'] - min)/(max- min)\n",
        "    tsg = tf.keras.preprocessing.sequence.TimeseriesGenerator(np.asanyarray(close), np.asanyarray(close),\n",
        "                              length=value_num,\n",
        "                              batch_size=len(close))\n",
        "    return tsg\n",
        "\n",
        "def create_model(n):\n",
        "    m = keras.Sequential()\n",
        "    m.add(layers.Dense(64, activation='relu', input_shape=(n,)))\n",
        "    m.add(layers.Dense(64, activation='relu'))\n",
        "    m.add(layers.Dense(1))\n",
        "    return m\n",
        "\n",
        "def train_models(model_options):\n",
        "    models = {}\n",
        "\n",
        "    for model_opt in model_options:\n",
        "        print('Using {} inputs'.format(model_opt[\"name\"]))\n",
        "\n",
        "        window_size = model_opt['window_size']\n",
        "        m = create_model(window_size)\n",
        "        print('Training...')\n",
        "        epochs = model_opt[\"epochs\"]\n",
        "        m.compile(optimizer='adam', loss='mse') \n",
        "\n",
        "        data = model_opt['data']\n",
        "\n",
        "        train_generator = generate_series(data[:-300], window_size)\n",
        "        val_generator = generate_series(data[-300:-100], window_size)\n",
        "\n",
        "        h = m.fit(train_generator,\n",
        "                  epochs=epochs,\n",
        "                  validation_data=val_generator)\n",
        "\n",
        "\n",
        "        model_opt_to_save = dict(model_opt)\n",
        "        del model_opt_to_save['data']\n",
        "        model_info = {'model': m, 'history': h.history, 'inputs': window_size, \"options\": model_opt_to_save}\n",
        "        models[window_size] = model_info\n",
        "    return models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DVcysstsnac"
      },
      "source": [
        "def filter_stocks(all_data, names):\n",
        "  filterd_data = all_data[all_data[\"Name\"] == names[0]]\n",
        "  for name in names[1:]:\n",
        "    filterd_data = filterd_data.append(all_data[all_data[\"Name\"] == name])\n",
        "  return filterd_data\n",
        "\n",
        "first_stock = filter_stocks(original_data, [\"AAL\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq3b8A_UvuX6"
      },
      "source": [
        "import pickle\n",
        "model_options = [\n",
        "                 {\"name\": 'one_stock_15', \"data\": first_stock, \"window_size\": 15, \"epochs\": 250},\n",
        "                 {\"name\": 'one_stock_20', \"data\": first_stock, \"window_size\": 20, \"epochs\": 250},\n",
        "                 {\"name\": 'one_stock_25', \"data\": first_stock, \"window_size\": 25, \"epochs\": 250},\n",
        "                 {\"name\": 'one_stock_35', \"data\": first_stock, \"window_size\": 35, \"epochs\": 250}\n",
        "                 ]\n",
        "trained_models = train_models(model_options)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fuIYnNKsqZX"
      },
      "source": [
        "from tensorflow.keras.losses import MeanSquaredError, MeanAbsoluteError, MeanAbsolutePercentageError\n",
        "\n",
        "mse = MeanSquaredError()\n",
        "mae = MeanAbsoluteError()\n",
        "mape = MeanAbsolutePercentageError()\n",
        "\n",
        "def convert_to_predict_input(data, offset, size, min, max):\n",
        "    data_from_known = np.asarray(data['close'])\n",
        "    normalized_data = (data_from_known - min)/(max- min)\n",
        "\n",
        "    finalized = normalized_data[offset:offset+size]\n",
        "    \n",
        "    return np.reshape(finalized, (1,size))\n",
        "\n",
        "model_stats = {}\n",
        "test_data = original_data[original_data.Name == \"GOOGL\"]\n",
        "# test_data = first_stock[-100:]\n",
        "# test_data = first_stock[-300:]\n",
        "# test_data = first_stock[5:]\n",
        "mae_val = []\n",
        "mape_val = []\n",
        "mse_val = []\n",
        "for k, v in trained_models.items():\n",
        "    model = v['model']    \n",
        "    window_size = v['inputs']\n",
        "    initial_offset = 35 - window_size\n",
        "\n",
        "    predicted_values = []\n",
        "    min = test_data.min()[\"close\"]\n",
        "    max = test_data.max()[\"close\"]\n",
        "    for i in range(250):\n",
        "        input_next = convert_to_predict_input(test_data[initial_offset+i:i+initial_offset+window_size], 0, window_size, min, max)\n",
        "        predicted_value = model.predict(input_next)[0][0]\n",
        "        predicted_values.append(predicted_value)\n",
        "\n",
        "\n",
        "    predicted_values_inversed = np.asarray(predicted_values) * (max-min) + min\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.set_title(v[\"options\"][\"name\"])\n",
        "\n",
        "    ax.plot(predicted_values_inversed, linestyle='dotted', color='blue')\n",
        "    ax.plot(np.asarray(test_data[initial_offset + window_size:initial_offset+window_size+(i+1)]['close']), color='green')\n",
        "\n",
        "    plt.legend(['Predicted price', 'Actual price'])\n",
        "    real_stock_price = test_data[initial_offset + window_size:initial_offset+window_size+(i+1)]['close']\n",
        "    mae_val.append(mae(real_stock_price, predicted_value).numpy())\n",
        "    mape_val.append(mape(real_stock_price, predicted_value).numpy())\n",
        "    mse_val.append(mse(real_stock_price, predicted_value).numpy())\n",
        "\n",
        "    print('mae', mae_val[-1])\n",
        "    print('mape', mape_val[-1])\n",
        "    print('mse', mse_val[-1])\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9qE7VEbSw9k"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.set_title(\"Mean squred error\")\n",
        "\n",
        "ax.plot(mse_val, linestyle='dotted', marker='o', color='blue')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}